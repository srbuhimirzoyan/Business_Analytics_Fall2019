{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic, Decision Tree, Random Forest and Gradient Boosting Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The following notebook provides an example code of predicting whether the student will have  <b> high</b> or <b> low</b> Final Grade using 4 different Classification Models. \n",
    "The dependent variable is <b>Final_Grade </b>, which is initially continuous variable but will be transformed to binary <b>(1-\"High grade\", 0-\"Low Grade\")</b>. \n",
    "\n",
    "<br>The general sequence of steps for the analysis the following:\n",
    "1. [Descriptive analysis](#pandas)\n",
    "2. [Linear, Decision Tree, Random Forest and Gradient Boosting Classification Models on Not transformed data](#stats)\n",
    "3. [Linear, Decision Tree, Random Forest and Gradient Boosting Classification Models on reduced data](#stats1)\n",
    "4. [Predicting for a new observation](#obs)\n",
    "5. [Conclusion](#stats2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2>1.Descriptive analysis</h2> <a name=\"pandas\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial data consists of 395 observations of 32 variables. There are no duplicates, missing values and variables with single value for all observations.\n",
    "We will first implement all 4 models on raw, unchanged data, observe the results and then perform the same analysis on transformed data.\n",
    "Our dependent variable is Final_Grade, which is numeric variable having values in [0;20] range. To be able to transform it into categorical, we examined variable distribution and found out that it is more or less equally spread around mean (10.4). Taking into account that median (11) is not too much far from the mean, we have decided to split the data based on the mean (rounded down, to 10, as there are only integers).\n",
    "After target transformation into binary, we can see that the category distribution is relatively balanced (1's are 53% and 0s are 47% of the data).\n",
    "\n",
    "**Note!** \n",
    "        1. We choose a common metric to compare model performance based on the data and analysis scope.\n",
    "        2. Winning model selection is done based on mean cross-validation score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:52.675586Z",
     "start_time": "2019-11-16T22:10:50.648014Z"
    }
   },
   "outputs": [],
   "source": [
    "#data manipulation and visualization libraries\n",
    "#for not showing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "\n",
    "#libraries for modelling and evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import accuracy_score,recall_score,confusion_matrix,classification_report,roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:52.898758Z",
     "start_time": "2019-11-16T22:10:52.678291Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing the data and making a dataframe\n",
    "data=pd.read_excel(\"Student_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.075226Z",
     "start_time": "2019-11-16T22:10:52.899694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(data.Final_Grade)\n",
    "plt.title(\"Final Grade distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.093215Z",
     "start_time": "2019-11-16T22:10:53.080215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    395.000000\n",
       "mean      10.415190\n",
       "std        4.581443\n",
       "min        0.000000\n",
       "25%        8.000000\n",
       "50%       11.000000\n",
       "75%       14.000000\n",
       "max       20.000000\n",
       "Name: Final_Grade, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Final_Grade.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.104147Z",
     "start_time": "2019-11-16T22:10:53.097169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Grade median: 11.0\n",
      "Final Grade mean: 10.415189873417722\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Grade median:\",data.Final_Grade.median())\n",
    "print(\"Final Grade mean:\",data.Final_Grade.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.112127Z",
     "start_time": "2019-11-16T22:10:53.106144Z"
    }
   },
   "outputs": [],
   "source": [
    "#transforming data :1-high grade and 0-low grade\n",
    "data.Final_Grade=np.where(data.Final_Grade>10,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.199892Z",
     "start_time": "2019-11-16T22:10:53.114122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>school2</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>Final_Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   StudentID school2 sex  age address famsize Pstatus  Medu  Fedu     Mjob  \\\n",
       "0          1      GP   F   18       U     GT3       A     4     4  at_home   \n",
       "1          2      GP   F   17       U     GT3       T     1     1  at_home   \n",
       "2          3      GP   F   15       U     LE3       T     1     1  at_home   \n",
       "3          4      GP   F   15       U     GT3       T     4     2   health   \n",
       "4          5      GP   F   16       U     GT3       T     3     3    other   \n",
       "\n",
       "      ...     internet romantic famrel  freetime  goout  Dalc Walc health  \\\n",
       "0     ...           no       no      4         3      4     1    1      3   \n",
       "1     ...          yes       no      5         3      3     1    1      3   \n",
       "2     ...          yes       no      4         3      2     2    3      3   \n",
       "3     ...          yes      yes      3         2      2     1    1      5   \n",
       "4     ...           no       no      4         3      2     1    2      5   \n",
       "\n",
       "  absences Final_Grade  \n",
       "0        6           0  \n",
       "1        4           0  \n",
       "2       10           0  \n",
       "3        2           1  \n",
       "4        4           0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#have a look at first rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.298630Z",
     "start_time": "2019-11-16T22:10:53.201886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>Final_Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>198.000000</td>\n",
       "      <td>16.696203</td>\n",
       "      <td>2.749367</td>\n",
       "      <td>2.521519</td>\n",
       "      <td>1.448101</td>\n",
       "      <td>2.035443</td>\n",
       "      <td>0.334177</td>\n",
       "      <td>3.944304</td>\n",
       "      <td>3.235443</td>\n",
       "      <td>3.108861</td>\n",
       "      <td>1.481013</td>\n",
       "      <td>2.291139</td>\n",
       "      <td>3.554430</td>\n",
       "      <td>5.708861</td>\n",
       "      <td>0.529114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>114.170924</td>\n",
       "      <td>1.276043</td>\n",
       "      <td>1.094735</td>\n",
       "      <td>1.088201</td>\n",
       "      <td>0.697505</td>\n",
       "      <td>0.839240</td>\n",
       "      <td>0.743651</td>\n",
       "      <td>0.896659</td>\n",
       "      <td>0.998862</td>\n",
       "      <td>1.113278</td>\n",
       "      <td>0.890741</td>\n",
       "      <td>1.287897</td>\n",
       "      <td>1.390303</td>\n",
       "      <td>8.003096</td>\n",
       "      <td>0.499785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>99.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>198.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>296.500000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        StudentID         age        Medu        Fedu  traveltime   studytime  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean   198.000000   16.696203    2.749367    2.521519    1.448101    2.035443   \n",
       "std    114.170924    1.276043    1.094735    1.088201    0.697505    0.839240   \n",
       "min      1.000000   15.000000    0.000000    0.000000    1.000000    1.000000   \n",
       "25%     99.500000   16.000000    2.000000    2.000000    1.000000    1.000000   \n",
       "50%    198.000000   17.000000    3.000000    2.000000    1.000000    2.000000   \n",
       "75%    296.500000   18.000000    4.000000    3.000000    2.000000    2.000000   \n",
       "max    395.000000   22.000000    4.000000    4.000000    4.000000    4.000000   \n",
       "\n",
       "         failures      famrel    freetime       goout        Dalc        Walc  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean     0.334177    3.944304    3.235443    3.108861    1.481013    2.291139   \n",
       "std      0.743651    0.896659    0.998862    1.113278    0.890741    1.287897   \n",
       "min      0.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      0.000000    4.000000    3.000000    2.000000    1.000000    1.000000   \n",
       "50%      0.000000    4.000000    3.000000    3.000000    1.000000    2.000000   \n",
       "75%      0.000000    5.000000    4.000000    4.000000    2.000000    3.000000   \n",
       "max      3.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "           health    absences  Final_Grade  \n",
       "count  395.000000  395.000000   395.000000  \n",
       "mean     3.554430    5.708861     0.529114  \n",
       "std      1.390303    8.003096     0.499785  \n",
       "min      1.000000    0.000000     0.000000  \n",
       "25%      3.000000    0.000000     0.000000  \n",
       "50%      4.000000    4.000000     1.000000  \n",
       "75%      5.000000    8.000000     1.000000  \n",
       "max      5.000000   75.000000     1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.328548Z",
     "start_time": "2019-11-16T22:10:53.300624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n",
      "Missing values: 0\n",
      "Single valued columns: Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#checking number of duplicates, missing values and columns with a single value\n",
    "print(\"Duplicates:\", data.duplicated().sum())\n",
    "print(\"Missing values:\", data.isna().sum().sum())\n",
    "print(\"Single valued columns:\", data.columns[data.nunique()==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.475156Z",
     "start_time": "2019-11-16T22:10:53.329545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's visualise the distribution of y\n",
    "plt.figure(figsize=(9,5))\n",
    "sns.countplot(data.Final_Grade)\n",
    "plt.title(\"Final grade distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.497099Z",
     "start_time": "2019-11-16T22:10:53.477150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    52.911392\n",
       "0    47.088608\n",
       "Name: Final grade distribution, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets count the benchmark for deposit subscription distribution\n",
    "#we have balanced data\n",
    "data.Final_Grade.value_counts(normalize=True).mul(100).rename(\"Final grade distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.543970Z",
     "start_time": "2019-11-16T22:10:53.501087Z"
    }
   },
   "outputs": [],
   "source": [
    "#Model building\n",
    "data_dum=pd.get_dummies(data,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.552949Z",
     "start_time": "2019-11-16T22:10:53.544968Z"
    }
   },
   "outputs": [],
   "source": [
    "Y=data_dum[\"Final_Grade\"]\n",
    "X=data_dum.drop(\"Final_Grade\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.562921Z",
     "start_time": "2019-11-16T22:10:53.554942Z"
    }
   },
   "outputs": [],
   "source": [
    "#splitting the data into train and test sets, as have small data will use 15% for the testing set\n",
    "X0, X1, Y0, Y1= train_test_split(X, Y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Linear, Decision Tree, Random Forest and Gradient Boosting Classification Models on Not transformed data</h2> <a name=\"stats\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T09:22:08.684212Z",
     "start_time": "2019-11-16T09:22:08.681218Z"
    }
   },
   "source": [
    "We are concerned to predict correctly both high and low final grades, so we will use `\"roc_auc\"` for scoring purposes, to ensure maximizing correct predictions for both of them. `\"roc_auc\"`score will also be our metric for choosing the winning model.\n",
    "The steps of model building using sklearn are the following:\n",
    "\n",
    "           1.Set parameter ranges based on model and Use GridSearchCV to find best parameters.Fit GridSearch on training set\n",
    "           2.Build(fit) the model on training set and calculate the needed score (in our case-\"roc_auc\") for training and \n",
    "              testing sets.\n",
    "              Note that we calculate `roc_auc`score based on probabilities!(use `predict_proba()`)*\n",
    "           3.Calculate the outlined metric (in our case-`roc_auc`) using `cross_val_score()`on the whole data (X and Y),\n",
    "              to be able to see the overall model performance.\n",
    "           4. Based on the results and best parameters, go back and adjust (tune) parameter ranges to get better scores on \n",
    "              train-test sets and for cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:53.574891Z",
     "start_time": "2019-11-16T22:10:53.565915Z"
    }
   },
   "outputs": [],
   "source": [
    "#setting Logistic regression parameters range\n",
    "param_logit={'class_weight':[None,'balanced'],\n",
    "            'C':np.linspace(0.001,5,100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:59.673616Z",
     "start_time": "2019-11-16T22:10:53.578879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 600 out of 600 | elapsed:    6.0s finished\n",
      "C:\\Users\\Srbuhi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'class_weight': [None, 'balanced'], 'C': array([1.00000e-03, 5.14949e-02, ..., 4.94951e+00, 5.00000e+00])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gridsearching to find best params\n",
    "#verbose is for showing this sentence-\"Fitting 3 folds for each of 200 candidates, totalling 600 fits\"\n",
    "gridsearch_logit = GridSearchCV(estimator=LogisticRegression(random_state=42),\n",
    "                        param_grid=param_logit,\n",
    "                        cv=3,scoring='roc_auc',verbose=1,n_jobs=2)\n",
    "gridsearch_logit.fit(X0,Y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:59.689574Z",
     "start_time": "2019-11-16T22:10:59.679600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.10198989898989898, 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best params for logit\n",
    "gridsearch_logit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:59.725476Z",
     "start_time": "2019-11-16T22:10:59.702537Z"
    }
   },
   "outputs": [],
   "source": [
    "#let's construct logit with the best parameters \n",
    "logit=LogisticRegression(class_weight=None,C=0.10198989898989898,random_state=42).fit(X0,Y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:59.744424Z",
     "start_time": "2019-11-16T22:10:59.730463Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting probabilities of being 1 (probability of having high final grade)\n",
    "Y0_logit=logit.predict_proba(X0)[:,1]\n",
    "Y1_logit=logit.predict_proba(X1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:59.808254Z",
     "start_time": "2019-11-16T22:10:59.748414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Train not scaled Logit: 0.79\n",
      "ROC_AUC Test not scaled Logit: 0.73\n",
      "Mean 3-fold ROC AUC score for not scaled logit: 0.6733333333333333\n"
     ]
    }
   ],
   "source": [
    "#calculating roc auc score\n",
    "print(\"ROC_AUC Train not scaled Logit:\",roc_auc_score(Y0,Y0_logit).round(2))\n",
    "print(\"ROC_AUC Test not scaled Logit:\",roc_auc_score(Y1,Y1_logit).round(2))\n",
    "print(\"Mean 3-fold ROC AUC score for not scaled logit:\",np.mean(cross_val_score(estimator=logit, X=X,y=Y,cv=3, scoring=\"roc_auc\").round(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:59.845157Z",
     "start_time": "2019-11-16T22:10:59.813241Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srbuhi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Srbuhi\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#Lets also scale and see whether the results will change\n",
    "sc=StandardScaler()\n",
    "numerics=data.select_dtypes(exclude=\"object\").drop(\"Final_Grade\", axis=1) #outlining only continuous variables for scaling\n",
    "                                                                         #and dropping Final_Grade as it is already 0 and 1  \n",
    "numerics=pd.DataFrame(sc.fit_transform(numerics), columns=numerics.columns.tolist())#making DF out of scaled numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:59.860115Z",
     "start_time": "2019-11-16T22:10:59.849146Z"
    }
   },
   "outputs": [],
   "source": [
    "#contatenating with the rest of the data \n",
    "data_sc=pd.concat([numerics,data.drop(numerics.columns.tolist(), axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:59.884053Z",
     "start_time": "2019-11-16T22:10:59.863107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 32 columns):\n",
      "StudentID      395 non-null float64\n",
      "age            395 non-null float64\n",
      "Medu           395 non-null float64\n",
      "Fedu           395 non-null float64\n",
      "traveltime     395 non-null float64\n",
      "studytime      395 non-null float64\n",
      "failures       395 non-null float64\n",
      "famrel         395 non-null float64\n",
      "freetime       395 non-null float64\n",
      "goout          395 non-null float64\n",
      "Dalc           395 non-null float64\n",
      "Walc           395 non-null float64\n",
      "health         395 non-null float64\n",
      "absences       395 non-null float64\n",
      "school2        395 non-null object\n",
      "sex            395 non-null object\n",
      "address        395 non-null object\n",
      "famsize        395 non-null object\n",
      "Pstatus        395 non-null object\n",
      "Mjob           395 non-null object\n",
      "Fjob           395 non-null object\n",
      "reason         395 non-null object\n",
      "guardian       395 non-null object\n",
      "schoolsup      395 non-null object\n",
      "famsup         395 non-null object\n",
      "paid           395 non-null object\n",
      "activities     395 non-null object\n",
      "nursery        395 non-null object\n",
      "higher         395 non-null object\n",
      "internet       395 non-null object\n",
      "romantic       395 non-null object\n",
      "Final_Grade    395 non-null int32\n",
      "dtypes: float64(14), int32(1), object(17)\n",
      "memory usage: 97.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#now we have scaled data of the same shape\n",
    "data_sc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:59.963839Z",
     "start_time": "2019-11-16T22:10:59.886048Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting dummies on scaled data\n",
    "data_sc=pd.get_dummies(data_sc, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:59.978798Z",
     "start_time": "2019-11-16T22:10:59.968826Z"
    }
   },
   "outputs": [],
   "source": [
    "#separating X and Y, \n",
    "#!!!Y is not scaled, just writing Y_sc to keep variable names consistent with the data\n",
    "Y_sc=data_sc[\"Final_Grade\"]\n",
    "X_sc=data_sc.drop(\"Final_Grade\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:10:59.996749Z",
     "start_time": "2019-11-16T22:10:59.984782Z"
    }
   },
   "outputs": [],
   "source": [
    "#train test split\n",
    "X0_sc, X1_sc, Y0_sc, Y1_sc=train_test_split(X_sc,Y_sc,test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:04.251406Z",
     "start_time": "2019-11-16T22:11:00.000739Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:    4.1s finished\n",
      "C:\\Users\\Srbuhi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#GridSearching Logit on scaled data\n",
    "gs_logit_scaled=GridSearchCV(estimator=LogisticRegression(random_state=42),param_grid=param_logit,\n",
    "                        scoring=\"roc_auc\",\n",
    "                        cv=3,verbose=1).fit(X0_sc,Y0_sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:04.258348Z",
     "start_time": "2019-11-16T22:11:04.252367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'class_weight': None}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logit_scaled.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:04.270316Z",
     "start_time": "2019-11-16T22:11:04.261342Z"
    }
   },
   "outputs": [],
   "source": [
    "logit_scaled=LogisticRegression(C=0.001, class_weight=None, random_state=42).fit(X0_sc,Y0_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:04.278296Z",
     "start_time": "2019-11-16T22:11:04.272348Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting probabilities for scaled data\n",
    "Y0_logit_sc=logit_scaled.predict_proba(X0_sc)[:,1]\n",
    "Y1_logit_sc=logit_scaled.predict_proba(X1_sc)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:04.311210Z",
     "start_time": "2019-11-16T22:11:04.281289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Train for Scaled logit: 0.71\n",
      "ROC_AUC Test for Scaled logit: 0.7\n",
      "Mean 3-fold ROC AUC score for Scaled logit: 0.6733333333333333\n"
     ]
    }
   ],
   "source": [
    "#calculating roc auc score and mean CV score: note that I haven't separately saved predicted probabilities\n",
    "print(\"ROC_AUC Train for Scaled logit:\",roc_auc_score(Y0,Y0_logit_sc).round(2))\n",
    "print(\"ROC_AUC Test for Scaled logit:\",roc_auc_score(Y1,Y1_logit_sc).round(2))\n",
    "print(\"Mean 3-fold ROC AUC score for Scaled logit:\",np.mean(cross_val_score(estimator=logit_scaled, X=X_sc,y=Y_sc,cv=3, scoring=\"roc_auc\").round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T19:57:18.791565Z",
     "start_time": "2019-11-16T19:57:18.784583Z"
    }
   },
   "source": [
    "<h3>Decision Tree Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:04.317192Z",
     "start_time": "2019-11-16T22:11:04.313202Z"
    }
   },
   "outputs": [],
   "source": [
    "#setting up the ranges for hyperparameters\n",
    "param_dt={\"max_depth\":range(1,10),\"min_samples_leaf\":range(4,84,5),\n",
    "          \"class_weight\":[\"balanced\", None],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:08.649643Z",
     "start_time": "2019-11-16T22:11:04.320184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 864 out of 864 | elapsed:    4.2s finished\n",
      "C:\\Users\\Srbuhi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': range(1, 10), 'min_samples_leaf': range(4, 84, 5), 'class_weight': ['balanced', None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-Validated Gridsearch using parameters, use n_jobs=-1 for faster computing and \n",
    "gs_dt=GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
    "                   param_grid=param_dt,scoring=\"roc_auc\",cv=3, verbose=1)\n",
    "gs_dt.fit(X0,Y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:08.656584Z",
     "start_time": "2019-11-16T22:11:08.651598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced', 'max_depth': 4, 'min_samples_leaf': 34}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see the optimal parameters\n",
    "gs_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:08.670897Z",
     "start_time": "2019-11-16T22:11:08.658578Z"
    }
   },
   "outputs": [],
   "source": [
    "#fitting the model with best parameters\n",
    "dt_grid=DecisionTreeClassifier(class_weight=\"balanced\",max_depth=4,\n",
    "                             min_samples_leaf=34, random_state=42).fit(X0,Y0)\n",
    "\n",
    "#getting probabilities\n",
    "Y0_dt_grid=dt_grid.predict_proba(X0)[:,1]\n",
    "Y1_dt_grid=dt_grid.predict_proba(X1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:08.697828Z",
     "start_time": "2019-11-16T22:11:08.671899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Train for Decision Tree: 0.72\n",
      "ROC_AUC Test for Decision Tree: 0.71\n",
      "Mean 3-fold ROC AUC score for Decision Tree: 0.64\n"
     ]
    }
   ],
   "source": [
    "#calculating roc auc score \n",
    "print(\"ROC_AUC Train for Decision Tree:\",roc_auc_score(Y0,Y0_dt_grid).round(2))\n",
    "print(\"ROC_AUC Test for Decision Tree:\",roc_auc_score(Y1,Y1_dt_grid).round(2))\n",
    "print(\"Mean 3-fold ROC AUC score for Decision Tree:\",np.mean(cross_val_score(estimator=dt_grid, X=X,y=Y,cv=3, scoring=\"roc_auc\")).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T20:05:00.653091Z",
     "start_time": "2019-11-16T20:05:00.647112Z"
    }
   },
   "source": [
    "<h3>Random Forest Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:08.704811Z",
     "start_time": "2019-11-16T22:11:08.699824Z"
    }
   },
   "outputs": [],
   "source": [
    "#setting rf param grid\n",
    "param_rf={  'max_depth': range(1,6),\n",
    "            'min_samples_leaf': range(4, 44, 5),\n",
    "             'class_weight': ['balanced', None] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:11.770999Z",
     "start_time": "2019-11-16T22:11:08.706806Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:    2.9s finished\n",
      "C:\\Users\\Srbuhi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': range(1, 6), 'min_samples_leaf': range(4, 44, 5), 'class_weight': ['balanced', None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Regression, using initial same parameters as for dt\n",
    "#Cross-Validated Gridsearch using parameters, use n_jobs=-1 for faster computing\n",
    "gs_rf=GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                   param_grid=param_rf,cv=3, scoring=\"roc_auc\", verbose=1)\n",
    "gs_rf.fit(X0,Y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:11.777979Z",
     "start_time": "2019-11-16T22:11:11.773036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None, 'max_depth': 2, 'min_samples_leaf': 4}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:11.798984Z",
     "start_time": "2019-11-16T22:11:11.779973Z"
    }
   },
   "outputs": [],
   "source": [
    "#fitting the model with best parameters\n",
    "rf=RandomForestClassifier(random_state=42,class_weight=None,max_depth=2,min_samples_leaf=4).fit(X0,Y0)\n",
    "\n",
    "#getting probabilities\n",
    "Y0_rf=rf.predict_proba(X0)[:,1]\n",
    "Y1_rf=rf.predict_proba(X1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:11.845841Z",
     "start_time": "2019-11-16T22:11:11.799920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Train for Random Forest: 0.73\n",
      "ROC_AUC Test for Random Forest: 0.65\n",
      "Mean 3-fold ROC AUC score for Random Forest: 0.62\n"
     ]
    }
   ],
   "source": [
    "#calculating roc auc score \n",
    "print(\"ROC_AUC Train for Random Forest:\",roc_auc_score(Y0,Y0_rf).round(2))\n",
    "print(\"ROC_AUC Test for Random Forest:\",roc_auc_score(Y1,Y1_rf).round(2))\n",
    "#Mean cross val score for model with default hyperparameters\n",
    "print(\"Mean 3-fold ROC AUC score for Random Forest:\",np.mean(cross_val_score(estimator=rf, X=X,y=Y,cv=3, scoring=\"roc_auc\",)).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T20:11:28.047368Z",
     "start_time": "2019-11-16T20:11:28.041414Z"
    }
   },
   "source": [
    "<h3>Gradient Boosting Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:11.850785Z",
     "start_time": "2019-11-16T22:11:11.846794Z"
    }
   },
   "outputs": [],
   "source": [
    "#gradient boosting doesn't have \"class_weight\" parameter, so setting new parameters dictionary\n",
    "param_gb={'max_depth': range(5, 21),\n",
    "          'min_samples_leaf': range(80, 125, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.102181Z",
     "start_time": "2019-11-16T22:11:11.853777Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 432 out of 432 | elapsed:   13.1s finished\n",
      "C:\\Users\\Srbuhi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': range(5, 21), 'min_samples_leaf': range(80, 125, 5)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Regression\n",
    "#Cross-Validated Gridsearch using parameters, use n_jobs=-1 for faster computing and \n",
    "gs_gb=GridSearchCV(estimator=GradientBoostingClassifier(random_state=42),param_grid=param_gb,cv=3, scoring=\"roc_auc\", verbose=1)\n",
    "gs_gb.fit(X0,Y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.109163Z",
     "start_time": "2019-11-16T22:11:25.104177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_leaf': 90}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.166351Z",
     "start_time": "2019-11-16T22:11:25.112155Z"
    }
   },
   "outputs": [],
   "source": [
    "#fitting the model with best parameters\n",
    "gb=GradientBoostingClassifier(random_state=42,max_depth=5,min_samples_leaf=90).fit(X0,Y0)\n",
    "#getting probabilities\n",
    "Y0_gb=gb.predict_proba(X0)[:,1]\n",
    "Y1_gb=gb.predict_proba(X1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.274453Z",
     "start_time": "2019-11-16T22:11:25.168350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Train for Tuned Gradient Boosting: 0.79\n",
      "ROC_AUC Test for Tuned Gradinet Boosting: 0.65\n",
      "Mean 3-fold ROC AUC score for Gradinet Boosting Tuned hyperparameters: 0.58\n"
     ]
    }
   ],
   "source": [
    "#calculating roc auc score \n",
    "print(\"ROC_AUC Train for Tuned Gradient Boosting:\",roc_auc_score(Y0,Y0_gb).round(2))\n",
    "print(\"ROC_AUC Test for Tuned Gradinet Boosting:\",roc_auc_score(Y1,Y1_gb).round(2))\n",
    "#Mean cross val score for model with default hyperparameters\n",
    "print(\"Mean 3-fold ROC AUC score for Gradinet Boosting Tuned hyperparameters:\",np.mean(cross_val_score(estimator=gb, X=X,y=Y,cv=3, scoring=\"roc_auc\",)).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.486339Z",
     "start_time": "2019-11-16T22:11:25.276280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 3-fold ROC AUC score for not scaled LOGIT: 0.6733333333333333\n",
      "Mean 3-fold ROC AUC score for Scaled LOGIT: 0.6733333333333333\n",
      "Mean 3-fold ROC AUC score for DT Tuned hyperparameters: 0.64\n",
      "Mean 3-fold ROC AUC score for Random Forest Tuned hyperparameters: 0.62\n",
      "Mean 3-fold ROC AUC score for Gradinet Boosting Tuned hyperparameters: 0.58\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean 3-fold ROC AUC score for not scaled LOGIT:\",np.mean(cross_val_score(estimator=logit, X=X,y=Y,cv=3, scoring=\"roc_auc\").round(2)))\n",
    "print(\"Mean 3-fold ROC AUC score for Scaled LOGIT:\",np.mean(cross_val_score(estimator=logit_scaled, X=X_sc,y=Y_sc,cv=3, scoring=\"roc_auc\").round(2)))\n",
    "print(\"Mean 3-fold ROC AUC score for DT Tuned hyperparameters:\",np.mean(cross_val_score(estimator=dt_grid, X=X,y=Y,cv=3, scoring=\"roc_auc\")).round(2))\n",
    "print(\"Mean 3-fold ROC AUC score for Random Forest Tuned hyperparameters:\",np.mean(cross_val_score(estimator=rf, X=X,y=Y,cv=3, scoring=\"roc_auc\",)).round(2))\n",
    "print(\"Mean 3-fold ROC AUC score for Gradinet Boosting Tuned hyperparameters:\",np.mean(cross_val_score(estimator=gb, X=X,y=Y,cv=3, scoring=\"roc_auc\",)).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T20:41:19.073064Z",
     "start_time": "2019-11-16T20:41:19.066083Z"
    }
   },
   "source": [
    "<h3>Linear, Decision Tree, Random Forest and Gradient Boosting Classification Models on reduced data </h3> <a name=\"stats2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I saved the data obtained from backward elimination into csv and will use it to reveal how the scorings change based on the quality of data. For backward elimination see https://nbviewer.jupyter.org/github/srbuhimirzoyan/Business_Analytics_Fall2019/blob/master/Session4/Session_4_Final..ipynb#select\n",
    "For the sake of simplicity and time saving, we will use the same best parameters we got for non-transformed data, to calculate the mean cross-val-score results. In other words, we will not perform new grid searches for every model, but will use already given best parameters for each model.**Note!** To have much better results, you should perform every step for the backward eliminated data as we did above.\n",
    "In any case, we can see that for reduced dataset and even without performing new grid searches, we have much higher results for \n",
    "mean 3-fold CV scores of all models, except gradient boosting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.498344Z",
     "start_time": "2019-11-16T22:11:25.488332Z"
    }
   },
   "outputs": [],
   "source": [
    "#reading backward eliminated data\n",
    "data_tr=pd.read_csv(\"backward_students.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.504564Z",
     "start_time": "2019-11-16T22:11:25.500610Z"
    }
   },
   "outputs": [],
   "source": [
    "#making Final grade categorical\n",
    "data_tr.Final_Grade=np.where(data_tr.Final_Grade>10,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.519550Z",
     "start_time": "2019-11-16T22:11:25.507557Z"
    }
   },
   "outputs": [],
   "source": [
    "#making dummies\n",
    "data_tr_dum=pd.get_dummies(data_tr, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.529527Z",
     "start_time": "2019-11-16T22:11:25.521549Z"
    }
   },
   "outputs": [],
   "source": [
    "#separating X and Y\n",
    "Y_tr=data_tr_dum[\"Final_Grade\"]\n",
    "X_tr=data_tr_dum.drop(\"Final_Grade\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.538503Z",
     "start_time": "2019-11-16T22:11:25.531522Z"
    }
   },
   "outputs": [],
   "source": [
    "#train-test split\n",
    "X0_tr,X1_tr,Y0_tr,Y1_tr=train_test_split(X_tr,Y_tr, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.561443Z",
     "start_time": "2019-11-16T22:11:25.540499Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srbuhi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Srbuhi\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#scaled data\n",
    "numerics_tr=data_tr.select_dtypes(exclude=\"object\").drop(\"Final_Grade\", axis=1) #outlining only continuous variables for scaling\n",
    "                                                                         #and dropping Final_Grade as it is already 0 and 1  \n",
    "numerics_tr=pd.DataFrame(sc.fit_transform(numerics_tr), columns=numerics_tr.columns.tolist())#making DF out of scaled numeric variables\n",
    "#contatenating with the rest of the data \n",
    "data_tr_scaled=pd.concat([numerics_tr,data_tr.drop(numerics_tr.columns.tolist(), axis=1)],axis=1)\n",
    "X_tr_sc=data_tr_scaled.drop(\"Final_Grade\", axis=1)\n",
    "Y_tr_sc=data_tr_scaled[\"Final_Grade\"]\n",
    "X0_tr_sc,X1_tr_sc,Y0_tr_sc,Y1_tr_sc=train_test_split(X_tr_sc,Y_tr_sc, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.625345Z",
     "start_time": "2019-11-16T22:11:25.571417Z"
    }
   },
   "outputs": [],
   "source": [
    "#outlining models with already got best params for not reduced data\n",
    "logit_tr=LogisticRegression(C=0.10198989898989898,class_weight=None, random_state=42).fit(X0_tr,Y0_tr)\n",
    "logit_tr_scaled=LogisticRegression(C=0.001, class_weight=None, random_state=42).fit(X0_tr_sc,Y0_tr_sc)\n",
    "dt_grid_tr=DecisionTreeClassifier(class_weight='balanced',max_depth=4,min_samples_leaf=34,random_state=42).fit(X0_tr,Y0_tr)\n",
    "rf_tr=RandomForestClassifier(class_weight=None, max_depth=2, min_samples_leaf=4, random_state=42).fit(X0_tr,Y0_tr)\n",
    "gb_tr=GradientBoostingClassifier(max_depth=5,min_samples_leaf=90,random_state=42).fit(X0_tr,Y0_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.808944Z",
     "start_time": "2019-11-16T22:11:25.626269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 3-fold ROC AUC score for not scaled LOGIT on reduced data: 0.7166666666666667\n",
      "Mean 3-fold ROC AUC score for Scaled LOGIT on reduced data: 0.7133333333333334\n",
      "Mean 3-fold ROC AUC score for DT Tuned hyperparameters on reduced data: 0.67\n",
      "Mean 3-fold ROC AUC score for Random Forest Tuned hyperparameters on reduced data: 0.67\n",
      "Mean 3-fold ROC AUC score for Gradinet Boosting Tuned hyperparameters on reduced data: 0.56\n"
     ]
    }
   ],
   "source": [
    "#summary of scores\n",
    "print(\"Mean 3-fold ROC AUC score for not scaled LOGIT on reduced data:\",np.mean(cross_val_score(estimator=logit_tr, X=X_tr,y=Y_tr,cv=3, scoring=\"roc_auc\").round(2)))\n",
    "print(\"Mean 3-fold ROC AUC score for Scaled LOGIT on reduced data:\",np.mean(cross_val_score(estimator=logit_tr_scaled, X=X_tr_sc,y=Y_tr_sc,cv=3, scoring=\"roc_auc\").round(2)))\n",
    "print(\"Mean 3-fold ROC AUC score for DT Tuned hyperparameters on reduced data:\",np.mean(cross_val_score(estimator=dt_grid_tr, X=X_tr,y=Y_tr,cv=3, scoring=\"roc_auc\")).round(2))\n",
    "print(\"Mean 3-fold ROC AUC score for Random Forest Tuned hyperparameters on reduced data:\",np.mean(cross_val_score(estimator=rf_tr, X=X_tr,y=Y_tr,cv=3, scoring=\"roc_auc\",)).round(2))\n",
    "print(\"Mean 3-fold ROC AUC score for Gradinet Boosting Tuned hyperparameters on reduced data:\",np.mean(cross_val_score(estimator=gb_tr, X=X_tr,y=Y_tr,cv=3, scoring=\"roc_auc\",)).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:29.744245Z",
     "start_time": "2019-11-16T21:33:29.738264Z"
    }
   },
   "source": [
    "<h3>Predicting for a new observation </h3> <a name=\"obs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example of prediction on a new observation, we will use reduced dataset.\n",
    "We want to predict Y, based on X. Thus, we have to provide values for our X.\n",
    "Let's see what our X test looks like, what columns it has, to provide similar ones to new observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.849836Z",
     "start_time": "2019-11-16T22:11:25.810940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Medu</th>\n",
       "      <th>failures</th>\n",
       "      <th>goout</th>\n",
       "      <th>absences</th>\n",
       "      <th>Mjob_health</th>\n",
       "      <th>Mjob_services</th>\n",
       "      <th>schoolsup_yes</th>\n",
       "      <th>famsup_yes</th>\n",
       "      <th>romantic_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>3.950000e+02</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.749367</td>\n",
       "      <td>0.334177</td>\n",
       "      <td>3.108861</td>\n",
       "      <td>3.199874e-01</td>\n",
       "      <td>0.086076</td>\n",
       "      <td>0.260759</td>\n",
       "      <td>0.129114</td>\n",
       "      <td>0.612658</td>\n",
       "      <td>0.334177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.094735</td>\n",
       "      <td>0.743651</td>\n",
       "      <td>1.113278</td>\n",
       "      <td>4.397442e-01</td>\n",
       "      <td>0.280832</td>\n",
       "      <td>0.439606</td>\n",
       "      <td>0.335751</td>\n",
       "      <td>0.487761</td>\n",
       "      <td>0.472300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.678637e-33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.354626e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.831564e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Medu    failures       goout      absences  Mjob_health  \\\n",
       "count  395.000000  395.000000  395.000000  3.950000e+02   395.000000   \n",
       "mean     2.749367    0.334177    3.108861  3.199874e-01     0.086076   \n",
       "std      1.094735    0.743651    1.113278  4.397442e-01     0.280832   \n",
       "min      0.000000    0.000000    1.000000  2.678637e-33     0.000000   \n",
       "25%      2.000000    0.000000    2.000000  3.354626e-04     0.000000   \n",
       "50%      3.000000    0.000000    3.000000  1.831564e-02     0.000000   \n",
       "75%      4.000000    0.000000    4.000000  1.000000e+00     0.000000   \n",
       "max      4.000000    3.000000    5.000000  1.000000e+00     1.000000   \n",
       "\n",
       "       Mjob_services  schoolsup_yes  famsup_yes  romantic_yes  \n",
       "count     395.000000     395.000000  395.000000    395.000000  \n",
       "mean        0.260759       0.129114    0.612658      0.334177  \n",
       "std         0.439606       0.335751    0.487761      0.472300  \n",
       "min         0.000000       0.000000    0.000000      0.000000  \n",
       "25%         0.000000       0.000000    0.000000      0.000000  \n",
       "50%         0.000000       0.000000    1.000000      0.000000  \n",
       "75%         1.000000       0.000000    1.000000      1.000000  \n",
       "max         1.000000       1.000000    1.000000      1.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.855820Z",
     "start_time": "2019-11-16T22:11:25.851831Z"
    }
   },
   "outputs": [],
   "source": [
    "#Based on the above data, let's define a new observation, aram, with the following values for respective columns\n",
    "aram=[[2,4,1,2,0,1,0,1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:11:25.867787Z",
     "start_time": "2019-11-16T22:11:25.858812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aram's grade based on Logit: [0]\n",
      "Aram's grade based on DT: [0]\n",
      "Aram's grade based on RF: [0]\n",
      "Aram's grade based on GB: [1]\n"
     ]
    }
   ],
   "source": [
    "#let's predict aram's final grade class using .predict()\n",
    "print(\"Aram's grade based on Logit:\",logit_tr.predict(aram))\n",
    "print(\"Aram's grade based on DT:\",dt_grid_tr.predict(aram))\n",
    "print(\"Aram's grade based on RF:\",rf_tr.predict(aram))\n",
    "print(\"Aram's grade based on GB:\",gb_tr.predict(aram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:59:54.748683Z",
     "start_time": "2019-11-16T21:59:54.743701Z"
    }
   },
   "source": [
    "Based on all Logit, DT and GB: Aram's grade belong to class 1 (\"high\"). According to Gradient Boosting, it will be class 0(\"low\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T22:01:41.937784Z",
     "start_time": "2019-11-16T22:01:41.931799Z"
    }
   },
   "source": [
    "<h3>Conclusion</h3> <a name=\"stats2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We performed 2 rounds of classification models: the first on not-transformed data, the second on data reduced via backward elimination.\n",
    "For the first round, we performed ***Logit, DT, RF, GB*** and ***Logit on scaled data***.\n",
    "For the second round, we performed same steps but for data reduced via backward elimination.\n",
    "According to results, models perform better when data does not contain redundant, not significant variables.\n",
    "Based on both rounds, according to mean 3-fold cross-validation score, the winning model is Logistic Regression on not scaled reduced dataset with 0.716 `roc_auc` score. The worst one is <u>gradient boosting.</u>\n",
    "We clearly saw that all tree-based models overfitted and one of the reasons may be small data, presence of a  lot of unnecessary variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
